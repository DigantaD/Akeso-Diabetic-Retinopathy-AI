# ğŸ§ Akeso: Modular Vision & Language System for Retinal Disease Diagnosis

> **One-liner:**
> A multi-task, modular AI pipeline for retinal fundus image diagnosis that integrates Grading, Segmentation, and Localization with LLM-powered clinical reports and interpretable visual outputs.

---

## âœ¨ Why Akeso?

Akeso addresses the need for a unified, interpretable, and role-aware diagnostic platform in diabetic retinopathy care:

* ğŸ”¹ Jointly performs **disease severity grading**, **lesion segmentation**, and **optic disc/fovea localization**
* ğŸ”¹ Combines **SAM's pretrained ViT** with custom decoders and **Graph Neural Networks**
* ğŸ”¹ Leverages **GPT-based LLMs** to explain results for **patients, doctors, and clinicians**
* ğŸ”¹ Designed to be **extensible**, lightweight, and capable of integrating with future modules (e.g., captioning, retrieval)

---

## ğŸ“Š Architecture Diagram

```
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚      ğŸ‘ï¸  Retinal Fundus Image Input      â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚   Vision Encoder (SAM / ViT) â”‚ â—„â”€â”€â”€â”€ Pretrained SAM ViT-B
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚             â”‚             â”‚
                          â–¼             â–¼             â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Disease Grading     â”‚ â”‚ Segmentation    â”‚ â”‚ Localization       â”‚
        â”‚ (MLP Head + GradCAM)â”‚ â”‚ (SAM + Decoder)â”‚ â”‚ (GNN + Heatmaps)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚             â”‚             â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–¼             â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ GPT-4o (LLM) Clinical Explanation â”‚
                     â”‚ - Role-based reporting           â”‚
                     â”‚ - Prompt Templates               â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  Modeling Approach & Design Choices

### âœ… Shared Vision Backbone (SAM ViT-B)

**Why SAM ViT-B?**

* Offers pretrained spatial reasoning and strong generalization from large-scale vision training.
* Facilitates seamless integration with Segment Anything's modular decoders.
* Eliminates the need to pretrain our own ViT from scratch for segmentation/localization.

### âœ… Grading Module

* MLP classification head with GradCAM visualization for interpretable disease severity classification.
* Why? Clinical explainability is crucial. GradCAM overlays help visualize retinal zones influencing the decision.

### âœ… Segmentation Module

* Combines SAM's mask decoder with a U-Net-style enhancement decoder.
* Why? SAM provides base instance awareness, but custom heads improve lesion-level fine-grained segmentation.

### âœ… Localization Module

* Uses patch-level GNN (GATv2Conv) + decoder to localize optic disc and fovea.
* Why? Coordinates alone are insufficient in fundus tasks. GNNs capture spatial patch dependencies for precise localization.

### âœ… LLM-Powered Report Generator

* GPT-4o based prompt templates produce role-specific explanations (patient, doctor, clinician).
* Why? Reports need to be adaptive, empathetic, and medically accurate for different user types.

---

## ğŸ“ Folder Structure (Simplified)

```
â”œâ”€â”€ agents/              # Embedding agents
â”œâ”€â”€ config/              # Task-wise configs
â”œâ”€â”€ dashboard/           # Streamlit-based multi-role UI
â”œâ”€â”€ models/              # Seg, Grade, Loc models
â”œâ”€â”€ outputs/             # Saved checkpoints (.pt)
â”œâ”€â”€ pretrained/          # Downloaded SAM ViT model
â”œâ”€â”€ segment-anything/    # Git-cloned Segment Anything repo
â”œâ”€â”€ tests/               # Evaluation scripts
â”œâ”€â”€ training/            # Training code + losses
â”œâ”€â”€ utils/               # GradCAM, WandB logger, postprocessing
â”œâ”€â”€ vision_etl/          # Data loaders for all 3 tasks
â”œâ”€â”€ app.py               # Unified Streamlit app entry
â”œâ”€â”€ run_all_tests.py     # Auto-run all test suites
â”œâ”€â”€ trainer.sh           # Script for full training loop
```

---

## âš™ï¸ Setup Instructions

```bash
# Clone main repo
$ git clone https://github.com/your-org/akeso-retina-ai.git
$ cd akeso-retina-ai

# Install core dependencies
$ pip install -r requirements.txt

# Install segment-anything
$ cd segment-anything && pip install -e . && cd ..

# Download pretrained SAM ViT model
$ mkdir -p pretrained
$ wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth -P pretrained/
```

---

## ğŸš€ Training

```bash
# Train individual modules
python training/train_grading.py --config config/grading_config.yaml
python training/train_segmentation.py --config config/segmentation_config.yaml
python training/train_localization.py --config config/localization_config.yaml

# Or run all via bash
bash trainer.sh
```

---

## ğŸ” Inference Dashboard

```bash
streamlit run app.py
```

**Dashboard Features:**

* Upload image(s) or .zip
* View:

  * Disease severity
  * Lesion masks
  * Optic disc/fovea heatmaps
  * GPT-4o report (role-aware)
* Select viewer mode: Patient / Doctor / Clinician

---

## ğŸ“Š Benchmarks (coming soon)

*You will be able to compare Akeso with global public models (MedPaLM, SAM, Gemini Flash, etc.) on metrics like accuracy, Dice score, localization error, explainability.*

---

## âš¡ Future Enhancements

* ğŸ”— Integrate RedisAI for faster inference caching
* ğŸ§  Add BLIP2/Gemini for caption-based diagnosis
* ğŸ› LoRA fine-tuning for lightweight deployment
* ğŸ  ONNX export for edge/mobile compatibility
* ğŸŒŸ Add support for longitudinal tracking + RAG memory

---

## ğŸ“œ License

MIT License. (c) 2025